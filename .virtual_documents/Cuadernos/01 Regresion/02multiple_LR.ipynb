import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


#Importar el Data Set
dataSet = pd.read_csv("50_Startups.csv")
X = dataSet.iloc[:, :-1]
y = dataSet.iloc[:, 4].values


X.head()


#Codificar datos categóricos
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
ct = ColumnTransformer(
    transformers=[('encoder', OneHotEncoder(), [3])],
    remainder='passthrough'
)
X = ct.fit_transform(X)


#Convertirlo en DataFrame para verlo con nombres de columnas
pd.DataFrame(X).head()


#Eliminar la primera columna Dummy para evitar colinealidad
X = X[:, 1:]



pd.DataFrame(X).head()


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)


print("X_train.shape = ", X_train.shape, " X.shape = ", X.shape)


#Ajustar el modelo RLM con Conjunto de Entrenamiento
from sklearn.linear_model import LinearRegression
regression = LinearRegression()
regression.fit(X_train, y_train)


#Visualizar el modelo de RLM que acabo de crear
from IPython.display import Markdown, display
b0 = regression.intercept_
coefs = regression.coef_

#Crear ecuacion dinámica
equation = f"y = {b0:.4f}"
for i, b in enumerate(coefs):
    equation += f" + {b:.4f}·x{i+1}"

display(Markdown(f"**{equation}**"))


#Prediccion de resultados en Conjunto de Testing
y_pred = regression.predict(X_test)


y_pred


y_test


#Construir el modelo óptimo de RLM usando Eliminación Hacia Atrás
import statsmodels.api as sm
#Se añade una columna de unos para que esta se multiplique con el "intercepto"; o sea, gracias a esto, damos lugar a la constante
X = np.append(arr = np.ones((50,1)).astype(int), values = X, axis = 1)
SL = 0.05


X_opt = X[:, [0,1,2,3,4,5]]
regression_OLS = sm.OLS(endog = y, exog = X_opt).fit()


regression_OLS.summary()


## from sklearn.metrics import r2_score
r2 = 
print("R2: ", r2)
